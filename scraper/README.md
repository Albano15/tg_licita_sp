# ğŸ³ Scraper com Node.js + Chromium + Cron

Este projeto roda um **scraper em Node.js** dentro de um container Docker, utilizando **Chromium** (para automaÃ§Ã£o com Puppeteer) e **cron** (para agendamento de tarefas).

---

## ğŸš€ PrÃ©-requisitos

- [Docker](https://docs.docker.com/get-docker/) instalado
- [Docker Compose](https://docs.docker.com/compose/)

---

## âš™ï¸ Executando o projeto com Docker Compose

Para executar o projeto, basta ter o Docker e o Docker Compose instalados e executar o seguinte comando na raiz do projeto:

```sh
docker-compose up -d
```

Este comando irÃ¡ construir as imagens e iniciar os containers em modo detached.

### Executando o scraper manualmente

Para executar o scraper manualmente, utilize o seguinte comando:

```sh
docker-compose exec scraper node scraper.js
```

Este comando irÃ¡ executar o script `scraper.js` dentro do container do scraper e irÃ¡ gerar os arquivos `output.json` e `screenshot.png` na pasta `scraper`.

### â° Gerenciando o cron

O container jÃ¡ inicia com o cron habilitado pelo entrypoint.sh.

Para verificar os logs do cron, utilize o seguinte comando:

```sh
docker-compose exec scraper tail -f /var/log/cron.log
```

## ğŸ“‚ Estrutura de pastas

.
â”œâ”€â”€ classes_dowload     # CÃ³digo relacionado ao scraping
â”œâ”€â”€ cron.d              # ConfiguraÃ§Ãµes de agendamento do cron
â”œâ”€â”€ docker/entrypoint.sh # Script que inicia cron + app
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â””â”€â”€ Dockerfile

## ğŸ“Œ VariÃ¡veis de ambiente

PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium â†’ Define o caminho do Chromium dentro do container.

## ğŸ“¡ Endpoints

O app expÃµe a porta 5000:

```
http://localhost:5000
```